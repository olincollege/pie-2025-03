<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BoxBot - Software & Firmware</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="nav">
        <a href="index.html">Home</a>
        <a href="electrical.html">Electrical</a>
        <a href="mechanical.html">Mechanical</a>
        <a href="software.html">Software/Firmware</a>
        <a href="budget.html">Budget (BOM)</a>
        <a href="journey.html">Journey & Design Process</a>
    </nav>

    <div class="main-content">
        <section class="section">
            <h2>Software Architecture & Logic</h2>
            <p class="summary-text">The BoxBot software stack is built with ROS2 and Python. When building our software, we prioritized development speed and expandability.</p>

            <div class="discipline-box initial-stage" style="border-left: 4px solid #d2691e;">
                <div class="box-header">
                    <h4>ðŸ”— SOURCE CODE REPOSITORY</h4>
                </div>
                <p>Access the full development history, libraries, and autonomous scripts here:</p>
                <a href="https://github.com/olincollege/BoxBot_Source" target="_blank" class="github-btn">View on GitHub</a>
            </div>

            <div class="phase-content">
                <div class="discipline-box soft">
                    <div class="box-header">
                        <h4>OS & ENVIRONMENT</h4>
                    </div>
                    <ul class="elec-list">
                        <li><strong>Raspberry Pi OS:</strong> Ubuntu 24.04, a Debian-based Linux environment.</li>
                        <li><strong>ROS2 Jazzy Jalisco:</strong> Robotics-focused software framework providing useful abstraction tools.</li>
                        <li><strong>Python 3.12:</strong> Primary language for autonomous logic and motor control.</li>
                    </ul>
                </div>

                <div class="discipline-box soft">
                    <div class="box-header">
                        <h4>LIBRARIES & TOOLS</h4>
                    </div>
                    <ul class="elec-list">
                        <li><strong>RealSense SDK:</strong> Enabling depth processing and spatial awareness for RealSense depth camera.</li>
                        <li><strong>pupil-apriltags:</strong> Python library used for April Tag detection and identification.</li>
                        <li><strong>gpiozero:</strong> Python library used for Raspberry Pi GPIO interaction.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section class="section">
            <h3>Autonomous State Machine</h3>
            <div class="full-width-details open">
                <div class="initial-content-wrapper">
                    <div class="initial-sub">
                        <h5>Detect, Approach, Squeeze Sequence</h5>
                        <p>The core firmware logic uses a Finite State Machine (FSM) to handle transitions between navigation and manipulation. This prevents mechanical stalls by ensuring the 'squeeze' only activates once the depth camera confirms payload proximity. Additionally, this allows for each state to be tested and validated individually, improving development speed.</p>
                    </div>
                    
                    

                    <div class="centered-image-container">
                        <video class="journey-main-img" controls muted loop>
                            <source src="media/jacksonsprint1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <p class="img-caption">Video 1: Testing PWM motor scaling and serial command latency.</p>
                    </div>
                </div>
            </div>
        </section>
        <section class="section">
            <h3>Software Architecture</h3>
            <div class="full-width-details open">
                <div class="initial-content-wrapper">
                    <div class="initial-sub">
                        <h5>ROS Diagram</h5>
                        <p>Diagram of our ROS system. Drive node handles direct GPIO interaction with motors and motor controllers. Teleoperation node captures keyboard input and sends motor commands. Computer vision node tracks state machine, processes image data, and sends motor commands. Both drive and computer vision nodes run on the Raspberry Pi, while the teleoperation node runs on on a laptop, connecting to the laptop over WiFi.</p>
                    </div>

                    <div class="centered-image-container">
                        <img src="media/ros_architecture.jpg" alt="Software architecture" class="journey-main-img">
                        <p class="img-caption">Software architecture with ROS</p>
                    </div>
                    <div class="initial-sub">
                        <h5>State Machine</h5>
                        <p>Our autonomous system uses state machine logic, shown in the diagram below.</p>
                    </div>

                    <div class="centered-image-container">
                        <img src="media/state_machine.jpg" alt="state machine" class="journey-main-img">
                        <p class="img-caption">State machine</p>
                    </div>
                </div>
            </div>
        </section>
    </div>
</body>
</html>
